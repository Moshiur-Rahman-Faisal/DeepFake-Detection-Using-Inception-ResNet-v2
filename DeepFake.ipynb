{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da422120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames [300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, 298, 300, 300, 300, 300, 300, 300, 300, 300, 300]\n",
      "Total number of videos:  400\n",
      "Average frame per video: 299.935\n"
     ]
    }
   ],
   "source": [
    "#To get the average frame count \n",
    "import json\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import copy\n",
    "video_files =  glob.glob('E:/Deep Fake/deepfake-detection-challenge/train_sample_videos/*.mp4')\n",
    "frame_count = []\n",
    "for video_file in video_files:\n",
    "  cap = cv2.VideoCapture(video_file)\n",
    "  if(int(cap.get(cv2.CAP_PROP_FRAME_COUNT))<150):\n",
    "    video_files.remove(video_file)\n",
    "    continue\n",
    "  frame_count.append(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "print(\"frames\" , frame_count)\n",
    "print(\"Total number of videos: \" , len(frame_count))\n",
    "print('Average frame per video:',np.mean(frame_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "41b37a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moshi\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5115271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to extract frame\n",
    "def frame_extract(path):\n",
    "  vidObj = cv2.VideoCapture(path) \n",
    "  success = 1\n",
    "  while success:\n",
    "      success, image = vidObj.read()\n",
    "      if success:\n",
    "          yield image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "from tqdm.autonotebook import tqdm\n",
    "# process the frames\n",
    "def create_face_videos(path_list,out_dir):\n",
    "  already_present_count =  glob.glob(out_dir+'*.mp4')\n",
    "  print(\"No of videos already present \" , len(already_present_count))\n",
    "  for path in tqdm(path_list):\n",
    "    out_path = os.path.join(out_dir,path.split('/')[-1])\n",
    "    file_exists = glob.glob(out_path)\n",
    "    if(len(file_exists) != 0):\n",
    "      print(\"File Already exists: \" , out_path)\n",
    "      continue\n",
    "    frames = []\n",
    "    flag = 0\n",
    "    face_all = []\n",
    "    frames1 = []\n",
    "    out = cv2.VideoWriter(out_path,cv2.VideoWriter_fourcc('M','J','P','G'), 30, (112,112))\n",
    "    for idx,frame in enumerate(frame_extract(path)):\n",
    "      #if(idx % 3 == 0):\n",
    "      if(idx <= 150):\n",
    "        frames.append(frame)\n",
    "        if(len(frames) == 4):\n",
    "          faces = face_recognition.batch_face_locations(frames)\n",
    "          for i,face in enumerate(faces):\n",
    "            if(len(face) != 0):\n",
    "              top,right,bottom,left = face[0]\n",
    "            try:\n",
    "              out.write(cv2.resize(frames[i][top:bottom,left:right,:],(112,112)))\n",
    "            except:\n",
    "              pass\n",
    "          frames = []\n",
    "    try:\n",
    "      del top,right,bottom,left\n",
    "    except:\n",
    "      pass\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc7980b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of videos already present  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88feb54f19914b169105f4dc1df1985d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_face_videos(video_files,'/content/drive/My Drive/FF_REAL_Face_only_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea89f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
